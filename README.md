# Chain-of-Thought Decoding with GPT-2

This project implements a simplified version of the *Chain-of-Thought Decoding* (CoTD) algorithm using the GPT-2 language model. The method explores multiple reasoning paths and aggregates answers across these paths to improve the robustness of final predictions. The detailed decoding explanation can be found here: https://arxiv.org/pdf/2402.10200


---

## Algorithm Overview

The goal of this decoding algorithm is to balance two key factors during generation:

1. **Token probability** – the likelihood of each token generated by the model.  
2. **Token transition consistency** – the difference in probability between a token and the next token across layers or steps.

The algorithm explores the *k-th* most probable reasoning paths and aggregates the final answers from each to make a final prediction. This is inspired by the idea that consistent reasoning across different paths can improve answer reliability.

---

## Model and Runtime Requirements

This implementation uses the **GPT-2** model, which is a relatively small transformer-based language model. It is suitable for lightweight testing and prototyping.

> Running this algorithm on larger models (e.g., GPT-J, LLaMA, Mistral) requires a significantly more powerful GPU and more memory due to the increased computational complexity of exploring and comparing multiple reasoning paths.

---

## How to Run

### Option 1: Google Colab

- Open the notebook in [Google Colab](https://colab.research.google.com).
- Provide your **Hugging Face access token** when prompted to load the GPT-2 model.

### Option 2: Local Environment

1. Clone or download this repository.
2. Run the file

---

## Datasets and Prompts

The project includes several example prompts designed to test simple reasoning tasks. These include:
- Basic control questions (e.g., “What should you do if...?”)
- Multiple-choice questions
- Simple logical or directional decision-making
The prompts are intentionally designed to be basic and straightforward to evaluate the decoding method’s effectiveness independently of model size.

---

## Observations

From initial testing:
The algorithm tends to generate ambiguous or divergent responses rather than a single, clearly correct answer.
It occasionally veers off-topic or includes loosely related reasoning.
While theoretically promising, the current implementation shows the limitations of GPT-2 for this task and highlights the need for stronger models and more refined scoring techniques.

---

## Notes
This code is experimental and meant for research, learning, and prototyping purposes.
